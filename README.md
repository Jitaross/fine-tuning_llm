# fine-tuning_llm

L'exécution préalable sans passer par llama se trouve lors du commit 2.
Avec llama c'est au commit 3 cependant, je n'ai pas réussi malgré tout mes efforts et les changements de paramètres, de taille de dataset, etc, à faire fonctionner le notebook... A chaque fois j'atteignais la limite de ram GPU donnée par google (et je n'ai pas une meilleure CG que ce que propose google).
